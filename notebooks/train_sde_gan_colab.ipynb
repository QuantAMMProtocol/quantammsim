{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SDE-GAN Training on GPU\n\nTrain a Neural SDE-GAN for synthetic multi-asset price path generation.\n\n**Runtime**: Go to Runtime > Change runtime type > **T4 GPU** (free tier) or A100 (Colab Pro).\n\nT4 (16GB): hidden=64, depth=2, batch=512, ~20min for 20k steps\nA100 (40GB): hidden=128, depth=3, batch=1024, ~10min for 20k steps\n\n**Data**: Minute-resolution price data is downloaded from Binance Vision (primary source)\nwith gap-filling from CryptoDataDownload, Coinbase, Gemini, etc. This takes ~10-15 min\non first run but the parquets are cached for the session."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if 'T4' in result.stdout:\n",
    "    GPU_TIER = 'T4'\n",
    "    print('Free T4 detected — using medium config')\n",
    "elif 'A100' in result.stdout or 'V100' in result.stdout:\n",
    "    GPU_TIER = 'A100'\n",
    "    print('High-end GPU detected — using full config')\n",
    "else:\n",
    "    GPU_TIER = 'T4'  # conservative default\n",
    "    print('Unknown GPU — defaulting to medium config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install deps\n!pip install -q jax[cuda12] equinox diffrax optax\n!pip install -q dask pandas pyarrow\n!pip install -q binance-historical-data Historic-Crypto bidask"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo\n",
    "import os\n",
    "if not os.path.exists('quantammsim'):\n",
    "    !git clone -b synthetic-price-gen https://github.com/QuantAMMProtocol/quantammsim.git\n",
    "os.chdir('quantammsim')\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify JAX sees GPU\n",
    "import jax\n",
    "print(f'JAX devices: {jax.devices()}')\n",
    "assert any(d.platform == 'gpu' for d in jax.devices()), 'No GPU! Change runtime type.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from quantammsim.synthetic.sde_gan import (\n",
    "    train_sde_gan, generate_paths, compute_daily_log_prices,\n",
    ")\n",
    "from quantammsim.utils.data_processing.historic_data_utils import get_historic_parquet_data"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Download minute-resolution price data\n# Uses the same pipeline as experiments/do_data_import.py:\n#   Binance Vision (primary) -> gap fill from other sources -> parquet\nimport os\nfrom pathlib import Path\nfrom quantammsim.utils.data_processing.historic_data_utils import update_historic_data\n\ntokens = ['ETH', 'BTC', 'USDC', 'PAXG']\nDATA_DIR = Path('quantammsim/data')\nDATA_DIR.mkdir(exist_ok=True)\ndata_dir_str = str(DATA_DIR) + '/'\n\nfor token in tokens:\n    parquet_path = DATA_DIR / f'{token}_USD.parquet'\n    if parquet_path.exists():\n        print(f'{token}_USD.parquet already exists, skipping download')\n        continue\n    print(f'Downloading {token}...')\n    update_historic_data(token, data_dir_str)\n    # update_historic_data writes to combined_data/ subdir, move to data root\n    combined_parquet = DATA_DIR / 'combined_data' / f'{token}_USD.parquet'\n    combined_daily = DATA_DIR / 'combined_data' / f'{token}_USD_daily.csv'\n    if combined_parquet.exists():\n        os.rename(str(combined_parquet), str(parquet_path))\n    if combined_daily.exists():\n        os.rename(str(combined_daily), str(DATA_DIR / f'{token}_USD_daily.csv'))\n    print(f'{token} done')\n\nprint('\\nParquet files:')\nfor f in sorted(DATA_DIR.glob('*.parquet')):\n    print(f'  {f.name} ({f.stat().st_size / 1e6:.1f} MB)')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tokens = ['ETH', 'BTC', 'USDC', 'PAXG']\n",
    "data_root = 'quantammsim/data'\n",
    "price_df = get_historic_parquet_data(tokens, cols=['close'], root=data_root)\n",
    "close_cols = [f'close_{t}' for t in tokens]\n",
    "minute_prices = price_df[close_cols].values.astype(np.float64)\n",
    "valid_mask = ~np.any(np.isnan(minute_prices), axis=1)\n",
    "first_valid = np.argmax(valid_mask)\n",
    "last_valid = len(valid_mask) - np.argmax(valid_mask[::-1])\n",
    "minute_prices = minute_prices[first_valid:last_valid]\n",
    "n_assets = len(tokens)\n",
    "minute_prices_jnp = jnp.array(minute_prices)\n",
    "daily_log = compute_daily_log_prices(minute_prices_jnp)\n",
    "n_days = daily_log.shape[0]\n",
    "\n",
    "real_returns = jnp.diff(daily_log, axis=0)\n",
    "real_drift = jnp.mean(real_returns, axis=0)\n",
    "real_vol = jnp.std(real_returns, axis=0)\n",
    "real_corr = jnp.corrcoef(real_returns.T)\n",
    "\n",
    "print(f'Data: {n_days} days, {n_assets} assets')\n",
    "for i, t in enumerate(tokens):\n",
    "    print(f'  {t}: drift={float(real_drift[i]):.6f}/day, vol={float(real_vol[i]):.6f}/day')\n",
    "print(f'\\nCorrelations:')\n",
    "for i in range(n_assets):\n",
    "    for j in range(i+1, n_assets):\n",
    "        print(f'  {tokens[i]}-{tokens[j]}: {float(real_corr[i,j]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Adjust these based on your GPU. The defaults auto-detect T4 vs A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_TIER == 'A100':\n",
    "    # A100 / V100 / Colab Pro\n",
    "    CONFIG = dict(\n",
    "        hidden_size=128, width_size=128, depth=3,\n",
    "        noise_size=12, initial_noise_size=12,\n",
    "        batch_size=1024, window_len=50,\n",
    "        n_steps=30000,\n",
    "        generator_lr=2e-5, discriminator_lr=1e-4,\n",
    "        drift_lambda=1.0,\n",
    "        use_reversible_heun=True,\n",
    "    )\n",
    "else:\n",
    "    # T4 (free tier) — 16GB VRAM\n",
    "    CONFIG = dict(\n",
    "        hidden_size=64, width_size=64, depth=2,\n",
    "        noise_size=8, initial_noise_size=8,\n",
    "        batch_size=512, window_len=50,\n",
    "        n_steps=20000,\n",
    "        generator_lr=2e-5, discriminator_lr=1e-4,\n",
    "        drift_lambda=1.0,\n",
    "        use_reversible_heun=True,\n",
    "    )\n",
    "\n",
    "print(f'Config ({GPU_TIER}):')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "t0 = time.time()\n",
    "\n",
    "generator, vol_scale, history = train_sde_gan(\n",
    "    minute_prices_jnp, n_assets=n_assets, key=key,\n",
    "    verbose=True, **CONFIG,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nDone in {elapsed:.0f}s ({elapsed/CONFIG[\"n_steps\"]*1000:.1f}ms/step)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = daily_log[0]\n",
    "key_eval = jax.random.PRNGKey(99)\n",
    "N_PATHS = 2000\n",
    "\n",
    "for horizon in [10, 30, 50, 100, 200]:\n",
    "    paths = generate_paths(generator, vol_scale, y0,\n",
    "                           n_days=horizon, n_paths=N_PATHS, key=key_eval)\n",
    "    y0_bc = jnp.broadcast_to(y0[:, None], (n_assets, N_PATHS))[None, ...]\n",
    "    full = jnp.concatenate([y0_bc, paths], axis=0)\n",
    "    returns = jnp.diff(full, axis=0)\n",
    "    drift = jnp.mean(returns, axis=(0, 2))\n",
    "    vol = jnp.mean(jnp.std(returns, axis=2), axis=0)\n",
    "\n",
    "    flat_ret = returns.transpose(0, 2, 1).reshape(-1, n_assets)\n",
    "    gen_corr = jnp.corrcoef(flat_ret.T)\n",
    "\n",
    "    print(f'\\n--- {horizon}-day paths ---')\n",
    "    for i, t in enumerate(tokens):\n",
    "        rd, rv = float(real_drift[i]), float(real_vol[i])\n",
    "        d, v = float(drift[i]), float(vol[i])\n",
    "        dr = d / rd if abs(rd) > 1e-8 else float('inf')\n",
    "        print(f'  {t}: drift={d:.6f} ({dr:.1f}x), vol={v:.6f} ({v/rv:.2f}x)')\n",
    "    print(f'  Correlations (real -> gen):')\n",
    "    for i in range(n_assets):\n",
    "        for j in range(i+1, n_assets):\n",
    "            print(f'    {tokens[i]}-{tokens[j]}: {float(real_corr[i,j]):.3f} -> {float(gen_corr[i,j]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Sweep (optional)\n",
    "\n",
    "Run this cell to sweep drift_lambda and find the optimal value for your GPU config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sweep drift_lambda\n",
    "SWEEP = False  # Set to True to run\n",
    "\n",
    "if SWEEP:\n",
    "    sweep_results = {}\n",
    "    for lam in [0.0, 0.1, 0.5, 1.0, 2.0]:\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'drift_lambda = {lam}')\n",
    "        print(f'{\"=\"*50}')\n",
    "        cfg = {**CONFIG, 'drift_lambda': lam}\n",
    "        key_s = jax.random.PRNGKey(42)\n",
    "        gen_s, vs_s, hist_s = train_sde_gan(\n",
    "            minute_prices_jnp, n_assets=n_assets, key=key_s,\n",
    "            verbose=True, **cfg,\n",
    "        )\n",
    "        # Quick 50d eval\n",
    "        paths_s = generate_paths(gen_s, vs_s, y0, n_days=50, n_paths=1000, key=key_eval)\n",
    "        y0_bc_s = jnp.broadcast_to(y0[:, None], (n_assets, 1000))[None, ...]\n",
    "        full_s = jnp.concatenate([y0_bc_s, paths_s], axis=0)\n",
    "        ret_s = jnp.diff(full_s, axis=0)\n",
    "        d_s = jnp.mean(ret_s, axis=(0, 2))\n",
    "        v_s = jnp.mean(jnp.std(ret_s, axis=2), axis=0)\n",
    "        flat_s = ret_s.transpose(0, 2, 1).reshape(-1, n_assets)\n",
    "        gc_s = jnp.corrcoef(flat_s.T)\n",
    "        sweep_results[lam] = {\n",
    "            'drift_ratios': {t: float(d_s[i])/float(real_drift[i]) if abs(float(real_drift[i])) > 1e-8 else float('inf') for i, t in enumerate(tokens)},\n",
    "            'vol_ratios': {t: float(v_s[i])/float(real_vol[i]) for i, t in enumerate(tokens)},\n",
    "            'eth_btc_corr': float(gc_s[0, 1]),\n",
    "        }\n",
    "\n",
    "    # Summary table\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print('SWEEP SUMMARY (50-day horizon)')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'{\"lambda\":>8} | {\"ETH drift\":>10} {\"BTC drift\":>10} {\"ETH-BTC corr\":>13}')\n",
    "    print('-' * 50)\n",
    "    for lam, r in sweep_results.items():\n",
    "        ed = r['drift_ratios'].get('ETH', 0)\n",
    "        bd = r['drift_ratios'].get('BTC', 0)\n",
    "        ec = r['eth_btc_corr']\n",
    "        print(f'{lam:>8.1f} | {ed:>9.1f}x {bd:>9.1f}x {ec:>12.3f} (real: 0.813)')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}