{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SDE-GAN Training on GPU\n\nTrain a Neural SDE-GAN for synthetic multi-asset price path generation.\n\n**Runtime**: Go to Runtime > Change runtime type > **T4 GPU** (free tier) or A100 (Colab Pro).\n\nT4 (16GB): hidden=64, depth=2, batch=512, ~20min for 20k steps\nA100 (40GB): hidden=128, depth=3, batch=1024, ~10min for 20k steps\n\n**Data**: You need minute-resolution parquet files (`ETH_USD.parquet`, etc.).\nThree options (pick one in the data cell below):\n1. **Google Drive** (recommended): upload parquets to Drive once, reuse across sessions\n2. **Direct upload**: use Colab file upload widget (~623 MB, a few minutes)\n3. **Download from Binance**: uses `update_historic_data` pipeline (~15-30 min)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if 'T4' in result.stdout:\n",
    "    GPU_TIER = 'T4'\n",
    "    print('Free T4 detected — using medium config')\n",
    "elif 'A100' in result.stdout or 'V100' in result.stdout:\n",
    "    GPU_TIER = 'A100'\n",
    "    print('High-end GPU detected — using full config')\n",
    "else:\n",
    "    GPU_TIER = 'T4'  # conservative default\n",
    "    print('Unknown GPU — defaulting to medium config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install deps\n!pip install -q jax[cuda12] equinox diffrax optax\n!pip install -q dask pandas pyarrow"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo\n",
    "import os\n",
    "if not os.path.exists('quantammsim'):\n",
    "    !git clone -b synthetic-price-gen https://github.com/QuantAMMProtocol/quantammsim.git\n",
    "os.chdir('quantammsim')\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify JAX sees GPU\n",
    "import jax\n",
    "print(f'JAX devices: {jax.devices()}')\n",
    "assert any(d.platform == 'gpu' for d in jax.devices()), 'No GPU! Change runtime type.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from quantammsim.synthetic.sde_gan import (\n",
    "    train_sde_gan, generate_paths, compute_daily_log_prices,\n",
    ")\n",
    "from quantammsim.utils.data_processing.historic_data_utils import get_historic_parquet_data"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =============================================================\n# DATA: pick ONE method, comment out the others\n# =============================================================\ntokens = ['ETH', 'BTC', 'USDC', 'PAXG']\nDATA_DIR = 'quantammsim/data'\nos.makedirs(DATA_DIR, exist_ok=True)\n\n# --- Option 1: Google Drive (recommended) --------------------\n# Upload parquets to Drive once (e.g. My Drive/quantammsim_data/),\n# then every session just mounts and copies.\nfrom google.colab import drive\ndrive.mount('/content/drive')\nDRIVE_DATA = '/content/drive/My Drive/quantammsim_data'  # adjust path\nfor t in tokens:\n    src = f'{DRIVE_DATA}/{t}_USD.parquet'\n    dst = f'{DATA_DIR}/{t}_USD.parquet'\n    if not os.path.exists(dst):\n        !cp \"{src}\" \"{dst}\"\n        print(f'Copied {t}_USD.parquet from Drive')\n    else:\n        print(f'{t}_USD.parquet already present')\n\n# --- Option 2: Direct upload ---------------------------------\n# Uncomment below, comment out Option 1 above.\n#\n# from google.colab import files\n# print('Upload: ETH_USD.parquet, BTC_USD.parquet, USDC_USD.parquet, PAXG_USD.parquet')\n# uploaded = files.upload()\n# for name, data in uploaded.items():\n#     with open(f'{DATA_DIR}/{name}', 'wb') as f:\n#         f.write(data)\n#     print(f'Saved {name} ({len(data)/1e6:.1f} MB)')\n\n# --- Option 3: Download from Binance Vision ------------------\n# Slow (~15-30 min) but fully automated. Uncomment below,\n# comment out Options 1 & 2, and add to the pip install cell:\n#   !pip install -q binance-historical-data Historic-Crypto bidask\n#\n# from quantammsim.utils.data_processing.historic_data_utils import update_historic_data\n# data_dir_str = DATA_DIR + '/'\n# for token in tokens:\n#     if os.path.exists(f'{DATA_DIR}/{token}_USD.parquet'):\n#         print(f'{token}_USD.parquet exists, skipping')\n#         continue\n#     print(f'Downloading {token}...')\n#     update_historic_data(token, data_dir_str)\n#     combined = f'{DATA_DIR}/combined_data/{token}_USD.parquet'\n#     if os.path.exists(combined):\n#         os.rename(combined, f'{DATA_DIR}/{token}_USD.parquet')\n#     print(f'{token} done')\n\n# Verify\nprint('\\nParquet files:')\nfor t in tokens:\n    p = f'{DATA_DIR}/{t}_USD.parquet'\n    if os.path.exists(p):\n        sz = os.path.getsize(p) / 1e6\n        print(f'  {t}_USD.parquet ({sz:.1f} MB)')\n    else:\n        print(f'  {t}_USD.parquet MISSING!')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tokens = ['ETH', 'BTC', 'USDC', 'PAXG']\n",
    "data_root = 'quantammsim/data'\n",
    "price_df = get_historic_parquet_data(tokens, cols=['close'], root=data_root)\n",
    "close_cols = [f'close_{t}' for t in tokens]\n",
    "minute_prices = price_df[close_cols].values.astype(np.float64)\n",
    "valid_mask = ~np.any(np.isnan(minute_prices), axis=1)\n",
    "first_valid = np.argmax(valid_mask)\n",
    "last_valid = len(valid_mask) - np.argmax(valid_mask[::-1])\n",
    "minute_prices = minute_prices[first_valid:last_valid]\n",
    "n_assets = len(tokens)\n",
    "minute_prices_jnp = jnp.array(minute_prices)\n",
    "daily_log = compute_daily_log_prices(minute_prices_jnp)\n",
    "n_days = daily_log.shape[0]\n",
    "\n",
    "real_returns = jnp.diff(daily_log, axis=0)\n",
    "real_drift = jnp.mean(real_returns, axis=0)\n",
    "real_vol = jnp.std(real_returns, axis=0)\n",
    "real_corr = jnp.corrcoef(real_returns.T)\n",
    "\n",
    "print(f'Data: {n_days} days, {n_assets} assets')\n",
    "for i, t in enumerate(tokens):\n",
    "    print(f'  {t}: drift={float(real_drift[i]):.6f}/day, vol={float(real_vol[i]):.6f}/day')\n",
    "print(f'\\nCorrelations:')\n",
    "for i in range(n_assets):\n",
    "    for j in range(i+1, n_assets):\n",
    "        print(f'  {tokens[i]}-{tokens[j]}: {float(real_corr[i,j]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Adjust these based on your GPU. The defaults auto-detect T4 vs A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_TIER == 'A100':\n",
    "    # A100 / V100 / Colab Pro\n",
    "    CONFIG = dict(\n",
    "        hidden_size=128, width_size=128, depth=3,\n",
    "        noise_size=12, initial_noise_size=12,\n",
    "        batch_size=1024, window_len=50,\n",
    "        n_steps=30000,\n",
    "        generator_lr=2e-5, discriminator_lr=1e-4,\n",
    "        drift_lambda=1.0,\n",
    "        use_reversible_heun=True,\n",
    "    )\n",
    "else:\n",
    "    # T4 (free tier) — 16GB VRAM\n",
    "    CONFIG = dict(\n",
    "        hidden_size=64, width_size=64, depth=2,\n",
    "        noise_size=8, initial_noise_size=8,\n",
    "        batch_size=512, window_len=50,\n",
    "        n_steps=20000,\n",
    "        generator_lr=2e-5, discriminator_lr=1e-4,\n",
    "        drift_lambda=1.0,\n",
    "        use_reversible_heun=True,\n",
    "    )\n",
    "\n",
    "print(f'Config ({GPU_TIER}):')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "t0 = time.time()\n",
    "\n",
    "generator, vol_scale, history = train_sde_gan(\n",
    "    minute_prices_jnp, n_assets=n_assets, key=key,\n",
    "    verbose=True, **CONFIG,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nDone in {elapsed:.0f}s ({elapsed/CONFIG[\"n_steps\"]*1000:.1f}ms/step)')"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Save trained model to Drive (survives disconnects/session restarts)\nimport equinox as eqx\nSAVE_DIR = '/content/drive/My Drive/quantammsim_data'\neqx.tree_serialise_leaves(f'{SAVE_DIR}/generator.eqx', generator)\nnp.save(f'{SAVE_DIR}/vol_scale.npy', np.array(vol_scale))\nprint(f'Model saved to {SAVE_DIR}/')\nprint(f'  generator.eqx + vol_scale.npy')\nprint(f'To reload in a new session, run the \"Load saved model\" cell below instead of retraining.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load saved model (skip training in a new session)\n# Uncomment this cell and skip the Train + Save cells above.\n#\n# import equinox as eqx\n# from quantammsim.synthetic.sde_gan import Generator\n# SAVE_DIR = '/content/drive/My Drive/quantammsim_data'\n# # Reconstruct skeleton with same architecture as CONFIG\n# skeleton = Generator(\n#     data_size=n_assets,\n#     initial_noise_size=CONFIG['initial_noise_size'],\n#     noise_size=CONFIG['noise_size'],\n#     hidden_size=CONFIG['hidden_size'],\n#     width_size=CONFIG['width_size'],\n#     depth=CONFIG['depth'],\n#     use_reversible_heun=CONFIG.get('use_reversible_heun', False),\n#     key=jax.random.PRNGKey(0),\n# )\n# generator = eqx.tree_deserialise_leaves(f'{SAVE_DIR}/generator.eqx', skeleton)\n# vol_scale = jnp.array(np.load(f'{SAVE_DIR}/vol_scale.npy'))\n# print(f'Loaded model from {SAVE_DIR}/')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = daily_log[0]\n",
    "key_eval = jax.random.PRNGKey(99)\n",
    "N_PATHS = 2000\n",
    "\n",
    "for horizon in [10, 30, 50, 100, 200]:\n",
    "    paths = generate_paths(generator, vol_scale, y0,\n",
    "                           n_days=horizon, n_paths=N_PATHS, key=key_eval)\n",
    "    y0_bc = jnp.broadcast_to(y0[:, None], (n_assets, N_PATHS))[None, ...]\n",
    "    full = jnp.concatenate([y0_bc, paths], axis=0)\n",
    "    returns = jnp.diff(full, axis=0)\n",
    "    drift = jnp.mean(returns, axis=(0, 2))\n",
    "    vol = jnp.mean(jnp.std(returns, axis=2), axis=0)\n",
    "\n",
    "    flat_ret = returns.transpose(0, 2, 1).reshape(-1, n_assets)\n",
    "    gen_corr = jnp.corrcoef(flat_ret.T)\n",
    "\n",
    "    print(f'\\n--- {horizon}-day paths ---')\n",
    "    for i, t in enumerate(tokens):\n",
    "        rd, rv = float(real_drift[i]), float(real_vol[i])\n",
    "        d, v = float(drift[i]), float(vol[i])\n",
    "        dr = d / rd if abs(rd) > 1e-8 else float('inf')\n",
    "        print(f'  {t}: drift={d:.6f} ({dr:.1f}x), vol={v:.6f} ({v/rv:.2f}x)')\n",
    "    print(f'  Correlations (real -> gen):')\n",
    "    for i in range(n_assets):\n",
    "        for j in range(i+1, n_assets):\n",
    "            print(f'    {tokens[i]}-{tokens[j]}: {float(real_corr[i,j]):.3f} -> {float(gen_corr[i,j]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Sweep (optional)\n",
    "\n",
    "Run this cell to sweep drift_lambda and find the optimal value for your GPU config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sweep drift_lambda\n",
    "SWEEP = False  # Set to True to run\n",
    "\n",
    "if SWEEP:\n",
    "    sweep_results = {}\n",
    "    for lam in [0.0, 0.1, 0.5, 1.0, 2.0]:\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'drift_lambda = {lam}')\n",
    "        print(f'{\"=\"*50}')\n",
    "        cfg = {**CONFIG, 'drift_lambda': lam}\n",
    "        key_s = jax.random.PRNGKey(42)\n",
    "        gen_s, vs_s, hist_s = train_sde_gan(\n",
    "            minute_prices_jnp, n_assets=n_assets, key=key_s,\n",
    "            verbose=True, **cfg,\n",
    "        )\n",
    "        # Quick 50d eval\n",
    "        paths_s = generate_paths(gen_s, vs_s, y0, n_days=50, n_paths=1000, key=key_eval)\n",
    "        y0_bc_s = jnp.broadcast_to(y0[:, None], (n_assets, 1000))[None, ...]\n",
    "        full_s = jnp.concatenate([y0_bc_s, paths_s], axis=0)\n",
    "        ret_s = jnp.diff(full_s, axis=0)\n",
    "        d_s = jnp.mean(ret_s, axis=(0, 2))\n",
    "        v_s = jnp.mean(jnp.std(ret_s, axis=2), axis=0)\n",
    "        flat_s = ret_s.transpose(0, 2, 1).reshape(-1, n_assets)\n",
    "        gc_s = jnp.corrcoef(flat_s.T)\n",
    "        sweep_results[lam] = {\n",
    "            'drift_ratios': {t: float(d_s[i])/float(real_drift[i]) if abs(float(real_drift[i])) > 1e-8 else float('inf') for i, t in enumerate(tokens)},\n",
    "            'vol_ratios': {t: float(v_s[i])/float(real_vol[i]) for i, t in enumerate(tokens)},\n",
    "            'eth_btc_corr': float(gc_s[0, 1]),\n",
    "        }\n",
    "\n",
    "    # Summary table\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print('SWEEP SUMMARY (50-day horizon)')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'{\"lambda\":>8} | {\"ETH drift\":>10} {\"BTC drift\":>10} {\"ETH-BTC corr\":>13}')\n",
    "    print('-' * 50)\n",
    "    for lam, r in sweep_results.items():\n",
    "        ed = r['drift_ratios'].get('ETH', 0)\n",
    "        bd = r['drift_ratios'].get('BTC', 0)\n",
    "        ec = r['eth_btc_corr']\n",
    "        print(f'{lam:>8.1f} | {ed:>9.1f}x {bd:>9.1f}x {ec:>12.3f} (real: 0.813)')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}